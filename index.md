---
layout: default
---

<!-- **\[UPDATE\]** We kindly ask you to fill in this [anonymous form](https://docs.google.com/forms/d/e/1FAIpQLSfuq7dJ6yWRrH9HaiWqsnVwQT2zZ_G1mtGSkxErz2kqYdRDqw/viewform?usp=preview) regarding the overall quality of the tutorial. As we are planning to present it to other venues, your feedback might be extremely important for us 🙏🙂 -->
<!-- 
## **Facilitators Team**
<p align="center">
  <table>
    <tr>
      <td align="center"><img src="assets/facilitators/DrD.jpg" width="220"><br>Dr. Dharshana Kasthurirathne<br>Sri Lanka Institute of Information Technology (SLIIT)<br>dharshana.k@sliit.lk</td>
      <td align="center"><img src="assets/facilitators/DrM.jpg" width="220"><br>Dr. Mahima Weerasinghe <br>Sri Lanka Institute of Information Technology (SLIIT)<br>mahima.w@sliit.lk</td>
       <td align="center"><img src="assets/facilitators/DrUoW.jpg" width="220"><br>Dr. Dinuka Sahabandu<br>University of Washington (UoW)<br>sdinuka@uw.edu</td>
    </tr>
    <tr>
      <td align="center"><img src="assets/facilitators/MrJ.jpg" width="220"><br>Mr. Jeewaka Perera<br>Sri Lanka Institute of Information Technology (SLIIT)<br>jeewaka.p@sliit.lk</td>
      <td align="center"><img src="assets/facilitators/MrA.jpg" width="220"><br>Mr. Asiri Gawesha<br>Sri Lanka Institute of Information Technology (SLIIT)<br>asiri.l@sliit.lk</td>  
      <td align="center"><img src="assets/facilitators/MrS.jpg" width="220"><br>Mr. Sanka Mohottala<br>Sri Lanka Institute of Information Technology (SLIIT)<br>sanka.m@sliit.lk</td>

      
    </tr>
  </table>
</p>

**\[UPDATE - 14/02/25\]** We kindly ask you to fill in this [anonymous form](https://docs.google.com/forms/d/e/1FAIpQLSfuq7dJ6yWRrH9HaiWqsnVwQT2zZ_G1mtGSkxErz2kqYdRDqw/viewform?usp=preview) regarding the overall quality of the tutorial. As we are planning to present it to other venues, your feedback might be extremely important for us 🙏🙂 -->

## Abstract

As deep learning models become increasingly complex, deploying them on resource-constrained devices poses significant challenges. Tiny Machine Learning (TinyML) addresses this by enabling ultra-compact, low-power AI models suitable for embedded systems and real-time sensor analytics. This workshop will introduce key model compression techniques, including pruning, quantization-aware training, post-training quantization, and knowledge distillation, along with efficient network design strategies. Through a blend of theory and hands-on sessions, participants will learn how to optimize and deploy deep learning models on embedded and mobile platforms, preparing them for practical applications in resource-limited environments.

<!-- 
## GNN Tutorial Schedule

| Time Duration         | Description                                      | Resource Person            |
|----------------------|------------------------------------------------|----------------------------|
| 08:30 AM - 08:35 AM | Introduction to tutorial                            |  Dr. Dharshana Kasthurirathna        |
| 08:35 AM – 09:25 AM | Introduction to GNN and its applications <br> Basic graph theory <br> Graph neural networks <br> Message passing GNN (MPGNN) | Dr. Mahima Weerasinghe    |
| 09:25 AM - 09:30 AM | **Break**                                      |                            |
| 09:30 AM – 10:20 AM | GCN architecture <br> GAT architecture     | Mr. Sanka Mohottala        |
| 10:20 AM – 11:00 AM | GNN application (Coding session)             | Mr. Asiri Gawesha          |
| 11:10 AM – 11:30 AM | New frontiers of GNN                         | Mr. Jeewaka Perera         |
| 11:30 AM – 11:40 AM | Q and A session                              | All resource persons will be present |



<!-- ## Workshop Agenda
### **Introduction**
- **Objective:** Welcome participants, introduce TinyML, and outline workshop goals.
- Agenda and logistics for the day.
- Brief discussion on the importance of TinyML in real-world applications.

### **TinyML Background and Compression Techniques**
- **Slides:** Overview of TinyML and key techniques:
  - Quantization
  - Pruning
  - Knowledge Distillation
- **Hands-On (Google Colab):**
  - Implement Post-Training Quantization (PTQ): Full integer, Float 16, and Dynamic range.
  - Compare PTQ with Quantization-Aware Training (QAT).
  - Pruning demonstration to reduce model size while retaining accuracy.

### **TinyML for Head Pose Estimation**
- **Slides:** Overview of the head pose estimation pipeline using TinyML.
- **Hands-On (Google Colab):**
  - Train and export a model for head pose estimation.
- **Android App Development:**
  - Guide participants to use Android Studio for building an app integrating the trained model.
  - **Note:** Ensure participants have Android Studio pre-installed.

### **Advanced Applications in TinyML** -->

<!-- ## Required Materials and Prerequisites
- A laptop with Google Colab access and Android Studio pre-installed.
- Basic understanding of machine learning and Python programming.
- Basic understanding of Android, Java, and Android Studio.
- Enthusiasm for exploring TinyML applications! -->

<!-- ## Outcomes
By the end of the workshop, participants will:
- Design and optimize TinyML models using state-of-the-art techniques.
- Deploy TinyML models on embedded devices and mobile applications.
- Identify advanced applications of TinyML. -->

<!-- **Closing remarks and Q&A**: 10 minutes -->

<!-- ## Additional useful material -->

<!-- | Title | Paper                                                                                     | Slides                                                                                    | Code                                                           | Venue     | Year |
|---|-------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------|----------------------------------------------------------------|----------|------|
| How Neighborhood Exploration Influences Novelty and Diversity in Graph Collaborative Filtering | [link](https://sisinflab.github.io/tutorial-gnns-recsys-log2023/assets/papers/MORS.pdf)   | [link](https://sisinflab.github.io/tutorial-gnns-recsys-log2023/assets/slides/MORS.pdf)   | [link](https://github.com/sisinflab/Novelty-Diversity-Graph)   | MORS @ RecSys  | 2022 |
| Auditing Consumer- and Producer-Fairness in Graph Collaborative Filtering | [link](https://sisinflab.github.io/tutorial-gnns-recsys-log2023/assets/papers/ECIR.pdf)   | [link](https://sisinflab.github.io/tutorial-gnns-recsys-log2023/assets/slides/ECIR.pdf)   | [link](https://github.com/sisinflab/ECIR2023-Graph-CF)         | ECIR           | 2023 |
| An Out-of-the-Box Application for Reproducible Graph Collaborative Filtering extending the Elliot Framework | [link](https://sisinflab.github.io/tutorial-gnns-recsys-log2023/assets/papers/UMAP.pdf)   | [link](https://sisinflab.github.io/tutorial-gnns-recsys-log2023/assets/slides/UMAP.pdf)   | [link](https://github.com/sisinflab/Graph-Demo)                | UMAP/GLB @ KDD | 2023 |
| Challenging the Myth of Graph Collaborative Filtering: a Reasoned and Reproducibility-driven Analysis | [link](https://sisinflab.github.io/tutorial-gnns-recsys-log2023/assets/papers/RecSys.pdf) | [link](https://sisinflab.github.io/tutorial-gnns-recsys-log2023/assets/slides/RecSys.pdf) | [link](https://github.com/sisinflab/Graph-RSs-Reproducibility) | RecSys         | 2023 |
| A Topology-aware Analysis of Graph Collaborative Filtering | [link](https://sisinflab.github.io/tutorial-gnns-recsys-log2023/assets/papers/arXiv.pdf)  |                                                                                           | [link](https://github.com/sisinflab/Graph-Characteristics)     | arXiv          | 2023 |
| Disentangling the Performance Puzzle of Multimodal-aware Recommender Systems | [link](https://sisinflab.github.io/tutorial-gnns-recsys-log2023/assets/papers/KDD.pdf) | [link](https://sisinflab.github.io/tutorial-gnns-recsys-log2023/assets/slides/KDD.pdf) | [link](https://github.com/sisinflab/MultiModal-Eval) | EvalRS@KDD | 2023 |
| On Popularity Bias of Multimodal-aware Recommender Systems: a Modalities-driven Analysis | [link](https://sisinflab.github.io/tutorial-gnns-recsys-log2023/assets/papers/MM.pdf)     |  [link](https://sisinflab.github.io/tutorial-gnns-recsys-log2023/assets/slides/MMIR.pdf)                                                                                          | [link](https://github.com/sisinflab/MultiMod-Popularity-Bias)  | MMIR @ MM      | 2023 |
| Formalizing Multimedia Recommendation through Multimodal Deep Learning | [link](https://dl.acm.org/doi/pdf/10.1145/3662738)   |                                                                                           | [link](https://github.com/sisinflab/Formal-MultiMod-Rec)                                                       | arXiv          | 2023 | -->

<!-- ## Facilitator Profiles -->

<!-- ### **Dr. Dharshana Kasthurirathne** -->
<!-- ![Dr. Dinuka Sahabandu](path/to/image.jpg) -->
<!-- Dharshana Kasthurirathna is an academic and researcher with a Doctor of Philosophy from the Complex Systems Research Group at the University of Sydney, Australia, specializing in complex
networks and evolutionary game theory. He also holds a master’s in computer science from the University of Colombo, and a BSc (Hons) in Computer Science and Engineering from the University of Moratuwa. Currently serving as an Assistant Professor at the Department of Computer Science, Faculty of Computing, Sri Lanka Institute of Information Technology (SLIIT), Dharshana’s research interests encompass evolutionary game theory, network science, machine learning, distributed systems, and optimization. In 2022, Dr.Kasthurirathna was the main presenter at the ”Graph Neural Networks: Theory and Applications” workshop, held as part of the 4th Inter-
national Conference on Advancements in Computing (ICAC). He also obtained a SLIIT research grant in 2023 as the principle investigator for developing a lightweight graph neural network based human action recognition framework. He is also a member of BrAIN Labs research group as well
as The Center of Excellence for AI (COE-AI) research group at SLIIT. -->

<!-- ### **Dr. Mahima Weerasighe**
Mahima Weerasighe obtained a first class honours in B.Eng. in Electronic Engineering from
Sheffield Hallam University, U.K., in 2011, and the M.Sc. degree in applied electronics from the
University of Colombo, Sri Lanka, in 2016. He completed his Ph.D. from Auckland University of
Technology, New Zealand in 2023 on Neuromorphic Computing. He has also completed Research
Assistantships in knowledge discovery research in predicting surgical outcomes and youth wellbe-
ing, in New Zealand. He has published his research in multiple journals including Nature and
IEEE. His research interests include using artificial intelligence techniques for human health and
wellbeing. His current research interests include spiking neural networks, brain data processing,
and computational neuroscience. He is a researcher of BrAIN Labs, a research and innovation
consortium established to develop AI solutions for real-world challenges. He is also a member of
the Center of Excellence for AI (COE-AI) research group at SLIIT -->

<!-- ### **Dr. Dinuka Sahabandu** -->
<!-- ![Dr. Dinuka Sahabandu](path/to/image.jpg) -->
<!-- Dinuka Sahabandu is a Senior Lecturer (HG) at the Department of Computer Science, Faculty of
Computing, Sri Lanka Institute of Information Technology (SLIIT). He received his Ph.D. from
the Department of Electrical and Computer Engineering at the University of Washington, Seattle,
WA, USA. He earned his B.S. and M.S. degrees in Electrical Engineering from Washington State
University, Pullman, WA, USA, in 2013 and 2016, respectively. His research interests include the
security and privacy of machine learning algorithms, applications of game theory and learning for
cybersecurity, and the control of multi-agent networks. He also share an interest in the theoretical
aspects of graph neural networks and the application of graph neural networks in his research
domains. He is also a member of BrAIN Labs research group as well as the Center of Excellence
for AI (COE-AI) research group at SLIIT. -->

<!-- ### **Mr.Jeewaka Perera**
Jeewaka Perera is a Senior Lecturer in the Department of Computer Science, Faculty of Computing,
Sri Lanka Institute of Information Technology, Malabe, Sri Lanka. His research interests include multi-objective combinatorial optimization, graph neural networks, and reinforcement learning.
His ongoing research includes Graph Neurual Networks, Graph Explainability and Biological AI. Mr. Perera received both his BSc. and MSc. in Computer Science from California State University,
Fresno. He is also a member of BrAIN Labs research group as well as the Center of Excellence for AI (COE-AI) research group at SLIIT. -->

<!-- ### **Mr. Sanka Mohottala** -->
<!-- ![Mr. Sanka Mohottala](path/to/image.jpg) -->
<!-- Sanka Mohottala is a Research Assistant and an MPhil candidate at Department of Computer
Science, Faculty of Computing ,Sri Lanka Institute of Information Technology (SLIIT). He obtained
his Bachelors in Electrical and Electronic Engineering in 2021 from SLIIT. His research interest are
in Graph Neural Networks (GNNs), data-efficient deep learning methods and computer Vision. He
has published in several conferences, including IEEE ICIT, TENCON and ICAC. He also served as
a reviewer for multiple conferences and a IEEE Transaction Journal. He also conducted the graph
neural networks related lectures in the Deep Learning module at SLIIT as a guest lecturer. He is
experienced in multiple graph neural network related frameworks like PyTorch Geometric, DGL
with hands-on experience in developing GNN-based models in multiple application domains. He
co-conducted a workshop named ”Graph Neural Networks: Theory and Applications” at the 4th
IEEE ICAC Conference. He also obtained a SLIIT research grant in 2023 as the a co-investigator
for developing a lightweight graph neural network based human action recognition framework. He
is also a member of BrAIN Labs research group as well as the Center of Excellence for AI (COE-AI)
research group at SLIIT. -->

<!-- ### **Mr. Asiri Gawesha** -->
<!-- ![Mr. Asiri Gawesha](path/to/image.jpg) -->
<!-- Asiri Gawesha is a Research Assistant and a MPhil candidate at the Department of Software
Engineering, Faculty of Computing, Sri Lanka Institute of Information Technology (SLIIT). He previously contributing to a World Bank-funded project on the Culturally Sensitive Autism Assessment Tool (CSAAT). He holds a BSc in Electrical and Electronic Engineering from SLIIT,
obtained in 2021. His research focuses on cutting-edge topics such as image processing, computer vision, edge computing, distributed computing, and cloud computing. His professional achievements include developing AI-powered autism screening tools, optimizing deep learning models for
edge devices, and leading mobile app integrations for machine learning inference. He has published as an author at conferences like TENCON, CCWC and ICAC and furthermore, he has been involved in peer-review activities for IEEE conferences. He share an interest in graph neural network
research areas like DeepSets and Transformers and have published work in those domains as well. He is also a member of BrAIN Labs research group as well as the Center of Excellence for AI
(COE-AI) research group at SLIIT. -->





<!-- ## Details of the presenters of this tutorial  
This tutorial is organized by the BrAIN Labs research group at SLIIT. All presenters are members
of this research group

| Name                          Mobile      | Email Address          |
|-------------------------------------------|------------------------|
| Dr. Mahima Weerasinghe        | 070462552  | mahima.w@sliit.lk     |
| Dr. Dharshana Kasthurirathna  | 0777671672 | dharshana.k@sliit.lk  |
| Dr. Dinuka Sahabandu          | 0777391621 | dinuka.s@sliit.lk     |
| Mr. Jeewaka Perera            | 0713771681 | jeewaka.p@sliit.lk    |
| Mr. Sanka Mohottala           | 0703975286 | sanka.m@sliit.lk      |
| Mr. Asiri Gawesha             | 0767616895 | asiri.l@sliit.lk      | -->

<!-- 
# Resources

 - [W. L. Hamilton, Graph Representation Learning Textbook](https://www.cs.mcgill.ca/~wlh/grl_book/)( freely available text book)
 - [CS224: Machine Learning with Graphs 2021, Lecture Notes](http://web.stanford.edu/class/cs224w/)
 - [Petar  Velickovic, Theoretical Foundations of Graph Neural Networks](https://www.youtube.com/watch?v=uF53xsT7mjc&t=2113s)
 - [PyTorch Geometric Tutorials](https://pytorch-geometric.readthedocs.io/en/latest/notes/colabs.html)
 - [Deep Graph Library Tutorials](https://docs.dgl.ai/guide/index.html) 
 - [Aleksa  Gordic, GNN research paper explanations](https://www.youtube.com/playlist?list=PLBoQnSflObckArGNhOcNg7lQG_f0ZlHF5)
 - [Learning on Graphs Conference, GNN oriented conference](https://logconference.org/)
 - [LoGaG: Learning on Graphs and Geometry Reading Group](https://hannes-stark.com/logag-reading-group)  
 -->

Stay tuned
